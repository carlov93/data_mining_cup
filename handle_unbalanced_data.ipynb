{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKING_DIR = os.getcwd()\n",
    "PATH_DATA = os.getcwd()+\"/Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "data_train = pd.read_csv(PATH_DATA + \"train_preprocessed.csv\", sep = \"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to handle unbalanced dataset?\n",
    "Class balancing techniques are only really necessary when we actually care about the minority classes. This is the case in the actual challange.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1775\n",
       "1     104\n",
       "Name: fraud, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.fraud.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The imbalance is quite huge: In 95% of purchases the buyer is honest, only 5% of purchases are frauds. \n",
    "\n",
    "The predicted solution will be assessed and compared based on their monetary value for the food retailer. The food retailer receives a profit of € 5 for every correctly identified fraud attempt. A costumer falsely accused of fraud, might not return to this store, which is denoted by a € 25 loss for the retailer.\n",
    "Assume no fraud is class 1 and fraud is class 2. The difficulty will be to avoid false positiv for class 1 and obtain a lot of true positiv for class 2.\n",
    "\n",
    "There severale methods to tackle this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method A - Cost-based classification\n",
    "- Weight balancing balances our data by altering the weight that each training example carries when computing the loss. \n",
    "- Normally, each example and class in our loss function will carry equal weight i.e 1.0.\n",
    "- But sometimes we might want certain classes or certain training examples to hold more weight if they are more important.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method B - Over and under sampling\n",
    "**Undersampling**\n",
    "- means we will select only some of the data from the majority class, only using as many examples as the minority class has. \n",
    "- This selection should be done to maintain the probability distribution of the class.\n",
    "\n",
    "**Oversampling**\n",
    "- means that we will create copies of our minority class in order to have the same number of examples as the majority class has. \n",
    "- The copies will be made such that the distribution of the minority class is maintained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataMiningCup",
   "language": "python",
   "name": "dataminingcup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
